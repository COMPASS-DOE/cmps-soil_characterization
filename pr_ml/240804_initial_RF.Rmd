---
title: "First looks at RF and MI"
author: "PR"
date: "2024-08-05"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F,
                      message = F,
                      warning = F)
```

#### Goals

##### Use Random Forest and Mutual Information analyses to understand BGC relationsips across synoptic sites

Both Random Forests (RF) and Mutual Information (MI) are designed to understand how multiple predictors relate to some dependent variable. Since we're interested in how parameters relate to each other across various delineations (regions, sites, transect locations), we'll be using these as our dependents. I'll start with Random Forests because I have more experience with them and they're easier to interpret IMO.

We'll construct RF models for

1.  CB v WLE
2.  UP v TR v W
3.  Each site

Because the goal is to understand relationships in biogeochemistry and not to predict a specific variable, we will not be splitting data into training and testing datasets. This means we **should not** interpret goodness-of-fit metrics as how well we can "predict" if a sample comes from a given location, but rather how well the variables used as predictors explain the variability in the dataset. This is something of a subtle difference, but I think an important one.

Note that I'm adding a white noise variable to all models. That's there as a guide for interpreting which variables are contributing more to the model than random chance.

```{r read in data}

#install_github("kaizadp/soilpalettes")

source("../2-code/0-packages.R")

require(pacman)
p_load(janitor, #I compulsively use clean_names()... sorry to add dependencie
       ranger, #actual RF algorithm
       PNWcolors, #change to your preferred color scheme, just using something familiar
       cowplot,
       tidymodels) #make modeling tidy again

## Read in data and add white noise as a diagnostic
df_raw <- read_csv("../1-data/processed/chemistry_combined_PCA.csv") %>% 
  clean_names() %>% 
  mutate(white_noise = rnorm(1:n(), mean = 0, sd = 1)) %>% 
  dplyr::select(-c(sample_label, tree_number)) 

## Losing 28 rows, primarily to ts, fe, p, but also some other stuff
# df_raw %>% #non-predictors
#   filter(if_any(everything(), is.na))

## We'll go with more vars over more rows for now
df <- df_raw %>% 
  drop_na()
```

### Random forest classification model results {.tabset}

```{r set up model function}

make_rf_model <- function(var){
  
  # 1) Dynamically create formula
  formula <- as.formula(paste(var, "~ ."))
  
  # 2) Tune mtry and ntree hyperparameters
  rf_spec <- rand_forest() %>%
    set_engine("ranger", importance = "impurity") %>% #using the ranger pkg instead of rf; importance needed for FI
    set_mode("classification")
  
  # 3) Define a recipe
  recipe <- recipe(formula, data = df) %>%
    step_integer(all_nominal_predictors()) %>% # integerize all dbl
    step_corr(all_predictors()) %>% # check correlations between predictors and remove any strong correlations
    step_normalize(all_predictors(), -all_outcomes()) # normalize non-normally distributed predictors
  
  # 4) Define a workflow
  wf <- workflow() %>%
    add_model(rf_spec) %>%
    add_recipe(recipe)
  
  # 5) Run the  model
  rf_model <- wf %>%
    update_model(rf_spec) %>%
    fit(data = df)
  
  ## Extract predictions
  predictions <- predict(rf_model, df) %>% rename("predicted" = .pred_class)
  
  ### Feature Importance
  ## Set vectors for renaming stuff
  var_names <- rf_model$fit$fit$fit$variable.importance
  
  ## Convert feature importance to a tibble with variables as a column
  fi0 <- as.data.frame(var_names) %>%
    tibble::rownames_to_column() %>%
    as_tibble() %>% 
    rename("predictor" = rowname, 
           "raw_fi" = var_names) %>% 
    mutate(fi_n = raw_fi / sum(raw_fi))
  
  ## Bind predictions to data
  prediction_df <- bind_cols(df, predictions)
  
  ## Return two things: how good the model did and which variables are most important
  return(list(predictions = prediction_df,
                feature_importance = fi0))
}
```

```{r set up wrapper plotting function}

# Wrapper function for plotting
plot_rf_results <- function(var, plot_title) {
  
  # Call the make_rf_model function
  model_results <- make_rf_model(var)
  
  ## Plot for classification equivalent to goodness-of-fit
  p1 <- ggplot(model_results$predictions, aes_string(x = var, y = "predicted")) + 
    geom_jitter(width = 0.2, 
                height = 0.2,
                alpha = 0.5) + 
    ggtitle(paste("Predictions:", var))
  
  ## Set up a color palette
  var_colors <- PNWColors::pnw_palette("Bay", n = length(unique(model_results$feature_importance$predictor)))
  
  ## Plot of feature importance
  p2 <- ggplot(model_results$feature_importance, aes(x = fi_n * 100, 
                                                     y = reorder(predictor, fi_n), 
                                                     fill = predictor)) + 
    geom_col(alpha = 0.8, show.legend = F, width = 0.7) + 
    scale_fill_manual(values = var_colors) + 
    labs(x = "Feature Importance (%)", 
         y = "", fill = "") + 
    ggtitle(paste("Feature Imp.:", var))
  
  ## Combine into a plot
  plot_grid(p1, p2, nrow = 1)
}

```

#### Between regions

```{r}
plot_rf_results("region")
```

**Initial thoughts - Region** 

  - looks like region was correctly predicted for all data 
  - NO3 as the most important seems sensible, a little surprised it wasn't salt-related though 
  - white noise near bottom (transect does not contribute more than random noise to the model so we should ignore it here)


#### Between transect locations

```{r}
plot_rf_results("transect")
```

**Initial thoughts - Transect** 

  - all but one correctly classified (one Transition looked like Upland) 
  - sulfate is interesting, maybe the relative transition in redox is more consistent than the relative transition in other things across CB and WLE sites 
  - neither horizon nor region is important to this model


#### Between sites

```{r}
plot_rf_results("site")
```

**Initial thoughts - Site** 
  
  - All correctly identified
  - NO3 and TN as top variables followed by region and horizon seems like a nice mix! Much less "one variable to rule them all" vibes
  - Transect not important to this model

### 

#### A couple quick cautions

1.  I haven't done classification RF before, so 1) there's probably a better way to quantify GOF, and 2) it would be good if we go this direction for me to take a bit of a deep dive into properly constructing and vetting an RF classification model.
2.  I'm a little suspicious that the models performed "too" good... I was expecting them to get maybe half of the values right, 100% makes me suspicious.
